{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252135 entries, 0 to 252134\n",
      "Columns: 198 entries, SK_ID_CURR to AVG_APPLICATION_AMOUNT\n",
      "dtypes: float64(141), int64(41), object(16)\n",
      "memory usage: 380.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       " 0      100002       1         Cash loans           M            N   \n",
       " 1      100003       0         Cash loans           F            N   \n",
       " 2      100004       0    Revolving loans           M            Y   \n",
       " 3      100006       0         Cash loans           F            N   \n",
       " 4      100007       0         Cash loans           M            N   \n",
       " \n",
       "   FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       " 0               Y             0          202500.0    406597.5      24700.5   \n",
       " 1               N             0          270000.0   1293502.5      35698.5   \n",
       " 2               Y             0           67500.0    135000.0       6750.0   \n",
       " 3               Y             0          135000.0    312682.5      29686.5   \n",
       " 4               Y             0          121500.0    513000.0      21865.5   \n",
       " \n",
       "    ...  DAYS_INSTALMENT_MEAN_y DAYS_INSTALMENT_MAX_y DAYS_INSTALMENT_MIN_y  \\\n",
       " 0  ...             -295.000000                 -25.0                -565.0   \n",
       " 1  ...            -1378.160000                -536.0               -2310.0   \n",
       " 2  ...             -754.000000                -724.0                -784.0   \n",
       " 3  ...             -252.250000                 -11.0                -545.0   \n",
       " 4  ...            -1028.606061                 -14.0               -2326.0   \n",
       " \n",
       "   DAYS_ENTRY_PAYMENT_MEAN_y DAYS_ENTRY_PAYMENT_MAX_y DAYS_ENTRY_PAYMENT_MIN_y  \\\n",
       " 0               -315.421053                    -49.0                   -587.0   \n",
       " 1              -1385.320000                   -544.0                  -2324.0   \n",
       " 2               -761.666667                   -727.0                   -795.0   \n",
       " 3               -271.625000                    -12.0                   -575.0   \n",
       " 4              -1032.242424                    -14.0                  -2318.0   \n",
       " \n",
       "    BUREAU_LOAN_COUNT  AVG_CREDIT_SUM  PREVIOUS_APPLICATION_COUNT  \\\n",
       " 0                8.0   108131.945625                         1.0   \n",
       " 1                4.0   254350.125000                         3.0   \n",
       " 2                2.0    94518.900000                         1.0   \n",
       " 3                NaN             NaN                         9.0   \n",
       " 4                1.0   146250.000000                         6.0   \n",
       " \n",
       "    AVG_APPLICATION_AMOUNT  \n",
       " 0               179055.00  \n",
       " 1               435436.50  \n",
       " 2                24282.00  \n",
       " 3               272203.26  \n",
       " 4               150530.25  \n",
       " \n",
       " [5 rows x 198 columns])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/shume/Downloads/CAP_Data/final_dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset and the first few rows\n",
    "data.info(), data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates in the SK_ID_CURR column to ensure that each key is unique.\n",
    "Look for any missing values in this key column, which might cause issues during data integration or matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate SK_ID_CURR: 0\n",
      "Missing SK_ID_CURR: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates and missing values in the SK_ID_CURR column\n",
    "duplicate_keys = data['SK_ID_CURR'].duplicated().sum()\n",
    "missing_keys = data['SK_ID_CURR'].isna().sum()\n",
    "print('Duplicate SK_ID_CURR:', duplicate_keys)\n",
    "print('Missing SK_ID_CURR:', missing_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that the features derived from external datasets like \"bureau\" and \"previous_application\" meaningfully contribute to your model, we can perform a few analyses:\n",
    "\n",
    "Assess the sparsity of these features to determine how much missing data each contains.\n",
    "Generate summary statistics for numerical features to get an overview of their distributions and identify any potential outliers or unusual patterns.\n",
    "Examine categorical features for the number of unique categories and the distribution of values within these categories.\n",
    "Consider strategies for dealing with missing data, such as imputation, creating binary indicators for missing data, or excluding features with excessive missingness if they do not add predictive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Missing Data Ratios:\n",
      "CNT_DRAWINGS_ATM_CURRENT_MEAN_x    0.79198\n",
      "AMT_DRAWINGS_ATM_CURRENT_MEAN_y    0.79198\n",
      "AMT_DRAWINGS_ATM_CURRENT_MEAN_x    0.79198\n",
      "CNT_DRAWINGS_ATM_CURRENT_MEAN_y    0.79198\n",
      "CNT_DRAWINGS_CURRENT_SUM_x         0.70561\n",
      "dtype: float64\n",
      "Numerical Columns:\n",
      "Index(['YEARS_EMPLOYED', 'CREDIT_INCOME_PERCENT', 'ANNUITY_INCOME_PERCENT',\n",
      "       'CREDIT_TERM', 'DAYS_EMPLOYED_PERCENT', 'BUREAU_LOAN_COUNT_x',\n",
      "       'AVG_CREDIT_SUM_x', 'PREVIOUS_APPLICATION_COUNT_x',\n",
      "       'AVG_APPLICATION_AMOUNT_x', 'AMT_BALANCE_MEAN_x', 'AMT_BALANCE_MAX_x',\n",
      "       'AMT_BALANCE_MIN_x', 'AMT_BALANCE_SUM_x',\n",
      "       'AMT_CREDIT_LIMIT_ACTUAL_MEAN_x', 'AMT_CREDIT_LIMIT_ACTUAL_MAX_x',\n",
      "       'AMT_DRAWINGS_ATM_CURRENT_MEAN_x', 'AMT_DRAWINGS_ATM_CURRENT_SUM_x',\n",
      "       'AMT_DRAWINGS_CURRENT_MEAN_x', 'AMT_DRAWINGS_CURRENT_SUM_x',\n",
      "       'AMT_PAYMENT_TOTAL_CURRENT_MEAN_x', 'AMT_PAYMENT_TOTAL_CURRENT_SUM_x',\n",
      "       'CNT_DRAWINGS_ATM_CURRENT_MEAN_x', 'CNT_DRAWINGS_ATM_CURRENT_SUM_x',\n",
      "       'CNT_DRAWINGS_CURRENT_MEAN_x', 'CNT_DRAWINGS_CURRENT_SUM_x',\n",
      "       'NUM_INSTALMENT_VERSION_MEAN_x', 'NUM_INSTALMENT_VERSION_SUM_x',\n",
      "       'NUM_INSTALMENT_NUMBER_MAX_x', 'AMT_INSTALMENT_MEAN_x',\n",
      "       'AMT_INSTALMENT_SUM_x', 'AMT_PAYMENT_MEAN_x', 'AMT_PAYMENT_SUM_x',\n",
      "       'DAYS_INSTALMENT_MEAN_x', 'DAYS_INSTALMENT_MAX_x',\n",
      "       'DAYS_INSTALMENT_MIN_x', 'DAYS_ENTRY_PAYMENT_MEAN_x',\n",
      "       'DAYS_ENTRY_PAYMENT_MAX_x', 'DAYS_ENTRY_PAYMENT_MIN_x',\n",
      "       'BUREAU_LOAN_COUNT_y', 'AVG_CREDIT_SUM_y',\n",
      "       'PREVIOUS_APPLICATION_COUNT_y', 'AVG_APPLICATION_AMOUNT_y',\n",
      "       'AMT_BALANCE_MEAN_y', 'AMT_BALANCE_MAX_y', 'AMT_BALANCE_MIN_y',\n",
      "       'AMT_BALANCE_SUM_y', 'AMT_CREDIT_LIMIT_ACTUAL_MEAN_y',\n",
      "       'AMT_CREDIT_LIMIT_ACTUAL_MAX_y', 'AMT_DRAWINGS_ATM_CURRENT_MEAN_y',\n",
      "       'AMT_DRAWINGS_ATM_CURRENT_SUM_y', 'AMT_DRAWINGS_CURRENT_MEAN_y',\n",
      "       'AMT_DRAWINGS_CURRENT_SUM_y', 'AMT_PAYMENT_TOTAL_CURRENT_MEAN_y',\n",
      "       'AMT_PAYMENT_TOTAL_CURRENT_SUM_y', 'CNT_DRAWINGS_ATM_CURRENT_MEAN_y',\n",
      "       'CNT_DRAWINGS_ATM_CURRENT_SUM_y', 'CNT_DRAWINGS_CURRENT_MEAN_y',\n",
      "       'CNT_DRAWINGS_CURRENT_SUM_y', 'NUM_INSTALMENT_VERSION_MEAN_y',\n",
      "       'NUM_INSTALMENT_VERSION_SUM_y', 'NUM_INSTALMENT_NUMBER_MAX_y',\n",
      "       'AMT_INSTALMENT_MEAN_y', 'AMT_INSTALMENT_SUM_y', 'AMT_PAYMENT_MEAN_y',\n",
      "       'AMT_PAYMENT_SUM_y', 'DAYS_INSTALMENT_MEAN_y', 'DAYS_INSTALMENT_MAX_y',\n",
      "       'DAYS_INSTALMENT_MIN_y', 'DAYS_ENTRY_PAYMENT_MEAN_y',\n",
      "       'DAYS_ENTRY_PAYMENT_MAX_y', 'DAYS_ENTRY_PAYMENT_MIN_y',\n",
      "       'BUREAU_LOAN_COUNT', 'AVG_CREDIT_SUM', 'PREVIOUS_APPLICATION_COUNT',\n",
      "       'AVG_APPLICATION_AMOUNT'],\n",
      "      dtype='object')\n",
      "Categorical Columns:\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Selecting columns from 123 onwards and calculating sparsity\n",
    "external_data_columns = data.columns[123:]\n",
    "missing_data_ratios = data[external_data_columns].isna().mean().sort_values(ascending=False)\n",
    "numerical_columns = data[external_data_columns].select_dtypes(include=['number']).columns  # Simplified to 'number'\n",
    "categorical_columns = data[external_data_columns].select_dtypes(include=['object']).columns\n",
    "\n",
    "# Displaying sparsity\n",
    "print('Top 5 Missing Data Ratios:')\n",
    "print(missing_data_ratios.head())\n",
    "print('Numerical Columns:')\n",
    "print(numerical_columns)\n",
    "print('Categorical Columns:')\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               count           mean            std  \\\n",
      "YEARS_EMPLOYED              252135.0       6.527552       6.402080   \n",
      "CREDIT_INCOME_PERCENT       252135.0       3.857996       2.572014   \n",
      "ANNUITY_INCOME_PERCENT      252123.0       0.177266       0.090983   \n",
      "CREDIT_TERM                 252123.0       0.053892       0.022521   \n",
      "DAYS_EMPLOYED_PERCENT       252135.0       0.156863       0.133548   \n",
      "...                              ...            ...            ...   \n",
      "DAYS_ENTRY_PAYMENT_MIN_y    238829.0   -1585.284061     910.505471   \n",
      "BUREAU_LOAN_COUNT           216475.0       5.583236       4.380794   \n",
      "AVG_CREDIT_SUM              216474.0  410034.843870  968767.042907   \n",
      "PREVIOUS_APPLICATION_COUNT  238466.0       4.781013       4.049168   \n",
      "AVG_APPLICATION_AMOUNT      238466.0  153068.174776  156237.954134   \n",
      "\n",
      "                                    min            25%            50%  \\\n",
      "YEARS_EMPLOYED                 0.002738       2.099932       4.511978   \n",
      "CREDIT_INCOME_PERCENT          0.004808       2.000000       3.181818   \n",
      "ANNUITY_INCOME_PERCENT         0.000224       0.112500       0.160333   \n",
      "CREDIT_TERM                    0.022073       0.037060       0.050000   \n",
      "DAYS_EMPLOYED_PERCENT          0.000042       0.056100       0.118734   \n",
      "...                                 ...            ...            ...   \n",
      "DAYS_ENTRY_PAYMENT_MIN_y   -4921.000000   -2470.000000   -1533.000000   \n",
      "BUREAU_LOAN_COUNT              1.000000       2.000000       4.000000   \n",
      "AVG_CREDIT_SUM                 0.000000  105592.175625  209182.815000   \n",
      "PREVIOUS_APPLICATION_COUNT     1.000000       2.000000       4.000000   \n",
      "AVG_APPLICATION_AMOUNT         0.000000   60752.812500  103813.937500   \n",
      "\n",
      "                                      75%           max  \n",
      "YEARS_EMPLOYED                   8.692676  4.904038e+01  \n",
      "CREDIT_INCOME_PERCENT            5.020000  3.669231e+01  \n",
      "ANNUITY_INCOME_PERCENT           0.224960  1.451571e+00  \n",
      "CREDIT_TERM                      0.064314  1.244296e-01  \n",
      "DAYS_EMPLOYED_PERCENT            0.219170  7.288115e-01  \n",
      "...                                   ...           ...  \n",
      "DAYS_ENTRY_PAYMENT_MIN_y      -716.000000 -3.000000e+00  \n",
      "BUREAU_LOAN_COUNT                8.000000  1.160000e+02  \n",
      "AVG_CREDIT_SUM              434217.508887  1.980723e+08  \n",
      "PREVIOUS_APPLICATION_COUNT       6.000000  7.300000e+01  \n",
      "AVG_APPLICATION_AMOUNT      188134.218750  4.050000e+06  \n",
      "\n",
      "[75 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for the numerical columns\n",
    "summary_statistics = data[numerical_columns].describe().transpose()\n",
    "print(summary_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's categorize the columns based on the percentage of missing data and suggest appropriate strategies for each category:\n",
    "\n",
    "Low Missingness (Less than 20%): Impute using simple methods like mean, median, or mode.\n",
    "Moderate Missingness (20% to 50%): Consider more sophisticated imputation methods or using placeholders if the feature is important.\n",
    "High Missingness (More than 50%): Evaluate the necessity of the feature. Consider excluding it or using model-based imputation if the feature is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Missingness: 40 columns\n",
      "Moderate Missingness: 0 columns\n",
      "High Missingness: 32 columns\n",
      "Column counts by missingness category: {'low': 40, 'moderate': 0, 'high': 32}\n"
     ]
    }
   ],
   "source": [
    "# Categorizing columns based on the percentage of missing data\n",
    "thresholds = {\n",
    "    'low': (0, 0.20),\n",
    "    'moderate': (0.20, 0.50),\n",
    "    'high': (0.50, 1.0)\n",
    "}\n",
    "missingness_categories = {\n",
    "    k: missing_data_ratios[(missing_data_ratios > v[0]) & (missing_data_ratios <= v[1])]\n",
    "    for k, v in thresholds.items()\n",
    "}\n",
    "\n",
    "# Display missingness categories\n",
    "for category, values in missingness_categories.items():\n",
    "    print(f'{category.capitalize()} Missingness: {len(values)} columns')\n",
    "\n",
    "# Count the number of columns in each category\n",
    "column_counts = {category: len(cols) for category, cols in missingness_categories.items()}\n",
    "\n",
    "# Output the number of columns in each category\n",
    "print('Column counts by missingness category:', column_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252135 entries, 0 to 252134\n",
      "Columns: 166 entries, SK_ID_CURR to AVG_APPLICATION_AMOUNT\n",
      "dtypes: float64(109), int64(41), object(16)\n",
      "memory usage: 319.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Check and impute for low missingness\n",
    "if 'low' in missingness_categories and not missingness_categories['low'].empty:\n",
    "    low_missing_numerical = [col for col in missingness_categories['low'].index if col in numerical_columns]\n",
    "    if low_missing_numerical:\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        data[low_missing_numerical] = imputer.fit_transform(data[low_missing_numerical])\n",
    "    else:\n",
    "        print(\"No numerical columns with low missingness to impute.\")\n",
    "\n",
    "# Drop high missingness columns\n",
    "if 'high' in missingness_categories and not missingness_categories['high'].empty:\n",
    "    high_missing_columns = list(missingness_categories['high'].index)\n",
    "    data.drop(columns=high_missing_columns, inplace=True)\n",
    "else:\n",
    "    print(\"No columns with high missingness to drop.\")\n",
    "\n",
    "# Optionally handle moderate missingness if it exists and is not empty\n",
    "if 'moderate' in missingness_categories and not missingness_categories['moderate'].empty:\n",
    "    moderate_missing_numerical = [col for col in missingness_categories['moderate'].index if col in numerical_columns]\n",
    "    if moderate_missing_numerical:\n",
    "        imputer_moderate = SimpleImputer(strategy='median')\n",
    "        data[moderate_missing_numerical] = imputer_moderate.fit_transform(data[moderate_missing_numerical])\n",
    "    else:\n",
    "        print(\"No numerical columns with moderate missingness to impute.\")\n",
    "\n",
    "# Check the dataframe structure after modifications\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Identify numerical and categorical columns with low missingness\n",
    "low_missing_categorical = [col for col in missingness_categories['low'].index if col in categorical_columns]\n",
    "\n",
    "# Imputing numerical data (already handled)\n",
    "# Now handling categorical data\n",
    "if low_missing_categorical:\n",
    "    imputer_categorical = SimpleImputer(strategy='most_frequent')  # or strategy='constant', fill_value='Unknown'\n",
    "    data[low_missing_categorical] = imputer_categorical.fit_transform(data[low_missing_categorical])\n",
    "\n",
    "# If you previously dropped high missingness columns and now want to handle categorical data separately\n",
    "# Redefine high missing columns excluding categorical ones, if you wish to keep some categorical columns with high missingness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], Series([], dtype: float64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rechecking and separating the categorical columns with low missingness for imputation\n",
    "low_missing_categorical = [col for col in missingness_categories['low'].index if col in data.select_dtypes(include=['object']).columns]\n",
    "\n",
    "# Imputing categorical data using the most frequent strategy\n",
    "if low_missing_categorical:\n",
    "    imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
    "    data[low_missing_categorical] = imputer_categorical.fit_transform(data[low_missing_categorical])\n",
    "\n",
    "# Confirm the successful imputation and check if any categorical columns still have missing values\n",
    "categorical_missing_after = data[low_missing_categorical].isna().sum()\n",
    "low_missing_categorical, categorical_missing_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMONAREA_AVG              175886\n",
       "COMMONAREA_MODE             175886\n",
       "COMMONAREA_MEDI             175886\n",
       "NONLIVINGAPARTMENTS_AVG     174759\n",
       "NONLIVINGAPARTMENTS_MODE    174759\n",
       "                             ...  \n",
       "EXT_SOURCE_2                   504\n",
       "AMT_GOODS_PRICE                256\n",
       "AMT_ANNUITY                     12\n",
       "CNT_FAM_MEMBERS                  2\n",
       "DAYS_LAST_PHONE_CHANGE           1\n",
       "Length: 67, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for remaining NaN values across all columns\n",
    "remaining_nans = data.isna().sum().sort_values(ascending=False)\n",
    "remaining_nans = remaining_nans[remaining_nans > 0]\n",
    "\n",
    "remaining_nans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Setting up imputers for numerical and categorical data\n",
    "numerical_imputer = SimpleImputer(strategy='median')  # Median imputation for numerical data\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')  # Most frequent for categorical data\n",
    "\n",
    "# Separating numerical and categorical columns with missing values\n",
    "numerical_columns_with_nans = data[remaining_nans.index].select_dtypes(include=['number']).columns\n",
    "categorical_columns_with_nans = data[remaining_nans.index].select_dtypes(include=['object']).columns\n",
    "\n",
    "# Applying the imputation\n",
    "if not numerical_columns_with_nans.empty:\n",
    "    data[numerical_columns_with_nans] = numerical_imputer.fit_transform(data[numerical_columns_with_nans])\n",
    "\n",
    "if not categorical_columns_with_nans.empty:\n",
    "    data[categorical_columns_with_nans] = categorical_imputer.fit_transform(data[categorical_columns_with_nans])\n",
    "\n",
    "# Check again for any remaining NaNs to ensure all have been handled\n",
    "final_check_nans = data.isna().sum().sum()\n",
    "final_check_nans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double-checking the entire dataset for any remaining NaN values\n",
    "overall_nans = data.isna().sum().sort_values(ascending=False)\n",
    "remaining_nans = overall_nans[overall_nans > 0]\n",
    "\n",
    "# Re-impute if necessary\n",
    "if not remaining_nans.empty:\n",
    "    # Using median imputation for any remaining numerical NaNs\n",
    "    remaining_numerical_columns = data[remaining_nans.index].select_dtypes(include=['number']).columns\n",
    "    if not remaining_numerical_columns.empty:\n",
    "        data[remaining_numerical_columns] = numerical_imputer.fit_transform(data[remaining_numerical_columns])\n",
    "\n",
    "# Rechecking for NaNs after re-imputation\n",
    "final_nan_check = data.isna().sum().sum()\n",
    "\n",
    "# Preparing features and target again\n",
    "X = data.drop('TARGET', axis=1)\n",
    "y = data['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Recheck for NaNs in X specifically\n",
    "nan_in_X = X.isna().sum().sum()\n",
    "final_nan_check, nan_in_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_CONTRACT_TYPE            int32\n",
       "CODE_GENDER                   int32\n",
       "FLAG_OWN_CAR                  int32\n",
       "FLAG_OWN_REALTY               int32\n",
       "NAME_TYPE_SUITE               int32\n",
       "NAME_INCOME_TYPE              int32\n",
       "NAME_EDUCATION_TYPE           int32\n",
       "NAME_FAMILY_STATUS            int32\n",
       "NAME_HOUSING_TYPE             int32\n",
       "OCCUPATION_TYPE               int32\n",
       "WEEKDAY_APPR_PROCESS_START    int32\n",
       "ORGANIZATION_TYPE             int32\n",
       "FONDKAPREMONT_MODE            int32\n",
       "HOUSETYPE_MODE                int32\n",
       "WALLSMATERIAL_MODE            int32\n",
       "EMERGENCYSTATE_MODE           int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data types to identify any categorical columns mistakenly left as 'object' type\n",
    "categorical_check = data.select_dtypes(include=['object'])\n",
    "categorical_columns = categorical_check.columns\n",
    "\n",
    "# If there are any categorical columns, we will apply Label Encoding\n",
    "if not categorical_columns.empty:\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_columns:\n",
    "        data[col] = le.fit_transform(data[col].astype(str))\n",
    "\n",
    "# Verifying the transformation\n",
    "transformed_categorical_check = data[categorical_columns].dtypes\n",
    "\n",
    "transformed_categorical_check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('              precision    recall  f1-score   support\\n\\n           0       0.91      1.00      0.95     46047\\n           1       0.55      0.00      0.00      4380\\n\\n    accuracy                           0.91     50427\\n   macro avg       0.73      0.50      0.48     50427\\nweighted avg       0.88      0.91      0.87     50427\\n',\n",
       " 0.5006306391533843)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-preparing the feature set and target after ensuring all data is numeric\n",
    "X = data.drop('TARGET', axis=1)\n",
    "y = data['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Retraining the Random Forest model with all data correctly encoded\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "classification_report_result = classification_report(y_test, predictions)\n",
    "auc_roc_score = roc_auc_score(y_test, predictions)\n",
    "\n",
    "classification_report_result, auc_roc_score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
